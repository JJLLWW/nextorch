{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6 - Multi-objective optimization for an ellipse function\n",
    "\n",
    "In this example, we will demonstrate how Bayesian Optimization can perform multi-objective optimization (MOO) and create a Pareto front. We will use a hyperthetical function which has a shape of an ellispe:\n",
    "\n",
    "$ y_1 = x $ and $ y_2 = \\sqrt{(1 - x^2/4)} $\n",
    "\n",
    "where $ y_1^2 + y_2^2/4 = 1 $. `x` is the only input parameter. `y1` and `y2` are two output reponses which cannot be optimized jointly. \n",
    "\n",
    "Multi-objective optimization derives a set of solutions that define the tradeoff between competing objectives. The boundary defined by the entire feasible solution set is called the Pareto front. \n",
    "\n",
    "In `nextorch`, we implement weighted sum method to construct the Pareto front. It is commonly used for convex problems. A set of objectives are scalarized to a single objective by adding each objective pre-multiplied by a user-supplied weight. The weight of an objective is chosen in proportion to its relative importance. The optimization is simply performed with respected to the scalarized objective. By varying the weight combinations, we can construct the whole Pareto front. \n",
    "\n",
    "For this example, the scalarized objective can be written as,\n",
    "$$ y = w_1 y_1 + w_2 y_2 $$\n",
    "where the weights $ w_1, w_2 \\in [0, 1] $ and $w_1 + w_2 = 1 $.\n",
    "\n",
    "The details of this example is summarized in the table below:\n",
    "\n",
    "| Key Item      | Description |\n",
    "| :----------------- | :----------------- |\n",
    "| Goal | Maximization, two objectives |\n",
    "| Objective function | Ellipse function |\n",
    "| Input (X) dimension | 1 |\n",
    "| Output (Y) dimension | 2 |\n",
    "| Analytical form available? | Yes |\n",
    "| Acqucision function | Expected improvement (EI) |\n",
    "| Initial Sampling | Latin hypercube | \n",
    "\n",
    "Next, we will go through each step in Bayesian Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import `nextorch` and other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nextorch import plotting, bo, doe, utils, io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the objective function and the design space\n",
    "We import the PFR model, and wrap it in a Python function called `PFR` as the objective function `objective_func`. \n",
    "\n",
    "The ranges of the input X are specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Define the objective function\n",
    "def ellipse(X_real):\n",
    "    \"\"\"ellipse function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_real : numpy matrix\n",
    "        input parameter\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Y_real: numpy matrix\n",
    "        y1 and y2\n",
    "    \"\"\"\n",
    "    if len(X_real.shape) < 2:\n",
    "        X_real = np.expand_dims(X_real, axis=1) #If 1D, make it 2D array\n",
    "        \n",
    "    y1 = X_real.copy()\n",
    "    y2 = np.sqrt(1 - X_real**2/4)\n",
    "    \n",
    "    Y_real = np.concatenate((y1, y2), axis = 1)\n",
    "        \n",
    "    return Y_real # y1, y2\n",
    "\n",
    "\n",
    "# Objective function\n",
    "objective_func = ellipse\n",
    "\n",
    "\n",
    "#%% Define the design space\n",
    "X_name = ['x']\n",
    "    \n",
    "# two outputs\n",
    "Y_names = [r'$\\rm y_1$', r'$\\rm y_2$']\n",
    "\n",
    "# combine X and Y names\n",
    "var_names = X_name + Y_names\n",
    "\n",
    "# Set the operating range for each parameter\n",
    "X_ranges =  [[0, 2]]\n",
    "\n",
    "# Get the information of the design space\n",
    "n_dim = 1 # the dimension of inputs\n",
    "n_objective = 2 # the dimension of outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the initial sampling plan\n",
    "Here we use LHC design with 10 points for the initial sampling. The initial reponse in a real scale `Y_init_real` is computed from the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial Sampling \n",
    "# Latin hypercube design with 10 initial points\n",
    "n_init_lhc = 10\n",
    "X_init_lhc = doe.latin_hypercube(n_dim = n_dim, n_points = n_init_lhc, seed= 1)\n",
    "# Get the initial responses\n",
    "Y_init_lhc = bo.eval_objective_func(X_init_lhc, X_ranges, objective_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize an `Experiment` object \n",
    "\n",
    "In this example, we use an `MOOExperiment` object, a class designed for multi-objective optimization. It can handle multiple weight combinations, perform the scalarized objective optimization automatically, and construct the entire Pareto front. \n",
    "\n",
    "An `MOOExperiment` is a subclass of `Experiment`. It requires all key components as `Experiment`:\n",
    "- Name of the experiment, used for output folder name\n",
    "- Input independent variables X: `X_init` or `X_init_real`\n",
    "- List of X ranges: `X_ranges`\n",
    "- Output dependent variables Y: `Y_init` or `Y_init_real`\n",
    "\n",
    "Optional:\n",
    "- `unit_flag`: `True` if the input X matrix is a unit scale, else `False`\n",
    "- `objective_func`: Used for test plotting\n",
    "- `maximize`: `True` if we look for maximum, else `False` for minimum\n",
    "\n",
    "Additionally, `weights` is required for `MOOExperiment.set_optim_specs` function. It defines a list of weights for objective 1. The weights of objective 2 is 1 minus that of objective 1. Under the hood, each weight combination correponds to a single `Experiment` object, each with a different scalarized objective. \n",
    "\n",
    "Some progress status will be printed out while initializing all single `Experiment` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing 21 experiments\n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 4.76 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 9.52 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 14.29 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 19.05 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 23.81 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 28.57 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 33.33 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 38.10 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 42.86 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 47.62 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 52.38 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 57.14 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 61.90 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 66.67 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 71.43 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 76.19 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 80.95 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 85.71 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 90.48 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 95.24 % \n",
      "Iter 10/100: 5.723519802093506\n",
      "Iter 20/100: 5.23295783996582\n",
      "Iter 30/100: 4.6133880615234375\n",
      "Iter 40/100: 1.9704277515411377\n",
      "Iter 50/100: 1.5127692222595215\n",
      "Iter 60/100: 1.410210371017456\n",
      "Iter 70/100: 1.32535719871521\n",
      "Iter 80/100: 1.2745541334152222\n",
      "Iter 90/100: 1.2467190027236938\n",
      "Iter 100/100: 1.226029396057129\n",
      "Initializing experiments 100.00 % \n",
      "Initializing 21 Experiments takes 0.23 minutes.\n"
     ]
    }
   ],
   "source": [
    "#%% Initialize an multi-objective Experiment object\n",
    "# Set its name, the files will be saved under the folder with the same name\n",
    "Exp_lhc = bo.MOOExperiment('ellipse_MOO')  \n",
    "# Import the initial data\n",
    "Exp_lhc.input_data(X_init_lhc, \n",
    "                   Y_init_lhc, \n",
    "                   X_ranges = X_ranges, \n",
    "                   X_names = X_name,\n",
    "                   Y_names = Y_names,\n",
    "                   unit_flag = False)\n",
    "\n",
    "# Set the optimization specifications \n",
    "# here we set the objective function, minimization by default\n",
    "# 10 weights, 10 Experiments\n",
    "n_exp = 21 # number of single Experiments\n",
    "\n",
    "# Set a weight vector for objective 1\n",
    "weights_obj_1 = np.linspace(0, 1, n_exp)\n",
    "weights_obj_2 = 1 - weights_obj_1\n",
    "\n",
    "# Set a timer\n",
    "start_time = time.time()\n",
    "Exp_lhc.set_optim_specs(objective_func = objective_func, \n",
    "                        maximize = True, \n",
    "                        weights = weights_obj_1)\n",
    "end_time = time.time()\n",
    "print('Initializing {} Experiments takes {:.2f} minutes.'.format(n_exp, (end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run trials \n",
    "\n",
    "At each weight combinations, we perform an optimization task for the scalarized objective (a single `Experiment`). `MOOExperiment.run_exp_auto` run these tasks automatically by using the default choice of acqucision function, Expected improvement (EI). It takes in the number of trials required for each `Experiment`. The number of trials needs to be large enough which allows Bayesian Optimization algorithm to converge to the optimum. Nevertheless, the optimization of `y1` and `y2` are rather trivial due to their simple analytical expression. We will do 10 trials for each experiment. The total number of calls for the objective function is `n_trails` * `n_exp` (=210). \n",
    "\n",
    "Some progress status will be printed out during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 21 experiments\n",
      "Iter 10/100: 0.5434869527816772\n",
      "Iter 20/100: 0.508520781993866\n",
      "Iter 30/100: 0.47558531165122986\n",
      "Iter 40/100: 0.45306968688964844\n",
      "Iter 50/100: 0.43230125308036804\n",
      "Iter 60/100: 0.4158894121646881\n",
      "Iter 70/100: 0.40274715423583984\n",
      "Iter 80/100: 0.3892427086830139\n",
      "Iter 90/100: 0.37743932008743286\n",
      "Running experiments 4.76 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.4873924255371094\n",
      "Iter 10/100: 2.468198299407959\n",
      "Running experiments 9.52 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Running experiments 14.29 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Running experiments 19.05 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.581068515777588\n",
      "Running experiments 23.81 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.6242969036102295\n",
      "Running experiments 28.57 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.6242969036102295\n",
      "Running experiments 33.33 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.6235032081604004\n",
      "Running experiments 38.10 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Running experiments 42.86 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.6235032081604004\n",
      "Running experiments 47.62 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.6235032081604004\n",
      "Running experiments 52.38 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.6251935958862305\n",
      "Running experiments 57.14 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Running experiments 61.90 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Running experiments 66.67 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Running experiments 71.43 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Running experiments 76.19 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 1.8618404865264893\n",
      "Iter 10/100: 3.462953567504883\n",
      "Running experiments 80.95 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Running experiments 85.71 % \n",
      "Iter 10/100: 1.3625149726867676\n",
      "Iter 20/100: 1.3488014936447144\n",
      "Iter 30/100: 1.3398540019989014\n",
      "Iter 40/100: 1.3346573114395142\n",
      "Iter 10/100: 3.4349498748779297\n",
      "Iter 10/100: 1.3757820129394531\n",
      "Running experiments 90.48 % \n",
      "Iter 10/100: 1.4361984729766846\n",
      "Iter 20/100: 1.4225883483886719\n",
      "Iter 10/100: 1.9328839778900146\n",
      "Iter 10/100: 3.8848330974578857\n",
      "Running experiments 95.24 % \n",
      "Iter 10/100: 3.950112819671631\n",
      "Running experiments 100.00 % \n",
      "Optimizing 21 Experiments takes 0.75 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Set the number of iterations for each experiments\n",
    "n_trials_lhc = 10 \n",
    "# Set a timer\n",
    "start_time = time.time()\n",
    "Exp_lhc.run_exp_auto(n_trials_lhc)\n",
    "\n",
    "end_time = time.time()\n",
    "print('Optimizing {} Experiments takes {:.2f} minutes.'.format(n_exp, (end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize the Pareto front\n",
    "We can get the Pareto set directly from the `MOOExperiment` object by using `MOOExperiment.get_optim`.\n",
    "\n",
    "To visualize the Pareto front, `y1` values are plotted against `y2` values. The scatter points resemble an ellispe shape, incidating the method is able to map out the entire front. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$\\rm w_1$</th>\n",
       "      <th>$\\rm w_2$</th>\n",
       "      <th>x</th>\n",
       "      <th>$\\rm y_1$</th>\n",
       "      <th>$\\rm y_2$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    $\\rm w_1$  $\\rm w_2$     x  $\\rm y_1$  $\\rm y_2$\n",
       "0        0.00       1.00  0.00       0.00       1.00\n",
       "1        0.05       0.95  0.26       0.26       0.99\n",
       "2        0.10       0.90  0.20       0.40       0.98\n",
       "3        0.15       0.85  0.33       0.66       0.94\n",
       "4        0.20       0.80  0.41       0.83       0.91\n",
       "5        0.25       0.75  1.14       1.14       0.82\n",
       "6        0.30       0.70  1.26       1.26       0.78\n",
       "7        0.35       0.65  0.73       1.47       0.68\n",
       "8        0.40       0.60  1.58       1.58       0.61\n",
       "9        0.45       0.55  1.68       1.68       0.54\n",
       "10       0.50       0.50  1.77       1.77       0.46\n",
       "11       0.55       0.45  1.87       1.87       0.35\n",
       "12       0.60       0.40  0.95       1.91       0.30\n",
       "13       0.65       0.35  0.95       1.91       0.30\n",
       "14       0.70       0.30  0.95       1.91       0.30\n",
       "15       0.75       0.25  0.95       1.91       0.30\n",
       "16       0.80       0.20  2.00       2.00       0.00\n",
       "17       0.85       0.15  1.98       1.98       0.15\n",
       "18       0.90       0.10  2.00       2.00       0.00\n",
       "19       0.95       0.05  2.00       2.00       0.00\n",
       "20       1.00       0.00  2.00       2.00       0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the set of optimal solutions\n",
    "Y_real_opts, X_real_opts = Exp_lhc.get_optim()\n",
    "weight_names = [r'$\\rm w_1$', r'$\\rm w_2$'] \n",
    "\n",
    "# Parse the optimum into a table\n",
    "data_opt = io.np_to_dataframe([weights_obj_1, weights_obj_2, X_real_opts, Y_real_opts], weight_names + var_names, n = n_exp)\n",
    "display(data_opt.round(decimals=2))\n",
    "\n",
    "# Make the pareto plots \n",
    "plotting.pareto_front_exp(Exp_lhc, fill = True, diagonal = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Thumbnail](_images/06.png) of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python383jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}